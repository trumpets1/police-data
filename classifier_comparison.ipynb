{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69117d8e",
   "metadata": {},
   "source": [
    "# Using Various Classifiers to predict arrests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94bbda0",
   "metadata": {},
   "source": [
    "Let's see how accurate it is.\n",
    "\n",
    "First, let's import all the necessary stuff, and import our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82775bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.predict as predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b463b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "police_data_2019 = pd.read_csv('data/preprocess/bayes_2019.csv')\n",
    "police_data_2021 = pd.read_csv('data/preprocess/bayes_2021.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8e029",
   "metadata": {},
   "source": [
    "Next, let's create our training and test sets, from the 2019 police data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8dbd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = predictions.cnb_process(police_data_2019)\n",
    "_, X_test_2021, _, y_test_2021 = predictions.cnb_process(police_data_2021, test_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10284f7",
   "metadata": {},
   "source": [
    "Let's create our first classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33fdcb9",
   "metadata": {},
   "source": [
    "## Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2922c6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb = predictions.cnb_predictor(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b179514",
   "metadata": {},
   "source": [
    "Now that we have a classifier based on our training data, let's see how good it is at predicting whether or not a given police report ends in an arrest.\n",
    "\n",
    "For starters, let's check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dc04a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 106468\n",
      "Misclassified: 3466\n",
      "Accuracy: 0.967445617462524\n"
     ]
    }
   ],
   "source": [
    "y_predicted = cnb.predict(X_test)\n",
    "missed = (y_test != y_predicted).sum()\n",
    "\n",
    "acc = accuracy_score(y_test, y_predicted)\n",
    "print(f'Original size: {X_test.shape[0]}')\n",
    "print(f'Misclassified: {missed}')\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc572295",
   "metadata": {},
   "source": [
    "Accuracy-wise, things seem to be okay.\n",
    "\n",
    "But let's look a little closer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3bd184",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d9398",
   "metadata": {},
   "source": [
    "Let's take a closer look. For starters, let's have a look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0002517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100596</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2479</td>\n",
       "      <td>2406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1\n",
       "0  100596   987\n",
       "1    2479  2406"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46783210",
   "metadata": {},
   "source": [
    "Next, let's have a look at the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce38e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.975950</td>\n",
       "      <td>0.990284</td>\n",
       "      <td>0.983064</td>\n",
       "      <td>101583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.709107</td>\n",
       "      <td>0.492528</td>\n",
       "      <td>0.581300</td>\n",
       "      <td>4885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.967446</td>\n",
       "      <td>0.967446</td>\n",
       "      <td>0.967446</td>\n",
       "      <td>0.967446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.842528</td>\n",
       "      <td>0.741406</td>\n",
       "      <td>0.782182</td>\n",
       "      <td>106468.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.963706</td>\n",
       "      <td>0.967446</td>\n",
       "      <td>0.964631</td>\n",
       "      <td>106468.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "0              0.975950  0.990284  0.983064  101583.000000\n",
       "1              0.709107  0.492528  0.581300    4885.000000\n",
       "accuracy       0.967446  0.967446  0.967446       0.967446\n",
       "macro avg      0.842528  0.741406  0.782182  106468.000000\n",
       "weighted avg   0.963706  0.967446  0.964631  106468.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, y_predicted, output_dict=True)\n",
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b8e4d",
   "metadata": {},
   "source": [
    "It seems that there are a lot of false negatives -- though it does pretty okay at tagging real positives!\n",
    "\n",
    "Let's compare to another classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902f30fa",
   "metadata": {},
   "source": [
    "## One-Class SVM (using stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa68cc3",
   "metadata": {},
   "source": [
    "Here, since I have a [fairly high number of samples](https://scikit-learn.org/stable/modules/outlier_detection.html), I'm going to use a one-class SVM using SGD.\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3f5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_fraction = y_train[y_train == 1].sum()  / y_train.shape[0]\n",
    "svm = predictions.oc_svm_predictor(X_train, anomaly_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0aa08",
   "metadata": {},
   "source": [
    "First, to do a little bit of reversal, since the classifier tags non-anomalies as 1, while tagging anomalies as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd1019fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_predictions = svm.predict(X_test)\n",
    "f = lambda x: 0 if x == 1 else 1\n",
    "f = np.vectorize(f)\n",
    "y_predicted_svm = f(original_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c07f78",
   "metadata": {},
   "source": [
    "Now, let's do everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5151d980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 106468\n",
      "Misclassified: 5914\n",
      "Accuracy: 0.9444527933275726\n"
     ]
    }
   ],
   "source": [
    "missed = (y_test != y_predicted_svm).sum()\n",
    "\n",
    "acc = accuracy_score(y_test, y_predicted_svm)\n",
    "print(f'Original size: {X_test.shape[0]}')\n",
    "print(f'Misclassified: {missed}')\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a42d00c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100553</td>\n",
       "      <td>1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4884</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1\n",
       "0  100553  1030\n",
       "1    4884     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, y_predicted_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d06a2402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.953678</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.971433</td>\n",
       "      <td>101583.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000970</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>4885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.944453</td>\n",
       "      <td>0.944453</td>\n",
       "      <td>0.944453</td>\n",
       "      <td>0.944453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.477324</td>\n",
       "      <td>0.495033</td>\n",
       "      <td>0.485885</td>\n",
       "      <td>106468.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.909966</td>\n",
       "      <td>0.944453</td>\n",
       "      <td>0.926877</td>\n",
       "      <td>106468.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score        support\n",
       "0              0.953678  0.989861  0.971433  101583.000000\n",
       "1              0.000970  0.000205  0.000338    4885.000000\n",
       "accuracy       0.944453  0.944453  0.944453       0.944453\n",
       "macro avg      0.477324  0.495033  0.485885  106468.000000\n",
       "weighted avg   0.909966  0.944453  0.926877  106468.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, y_predicted_svm, output_dict=True)\n",
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2e4c5",
   "metadata": {},
   "source": [
    "Absolutely not good at all. Almost no positives were correctly classified, and there were too many false positives to go along with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
